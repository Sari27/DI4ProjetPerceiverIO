{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Etude scientifique du PerceiverIO\n",
    "### Sujet de Nicolas Ragot - Polytech Tours\n",
    "\n",
    "**Etudiants :**\n",
    "- Theo Boisseau (theo.boisseau@etu.univ-tours.fr)\n",
    "- Sarah Denis (sarah.denis-2@etu.univ-tours.fr)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Description:\n",
    "\n",
    "Ce Notebook vient en complément du rapport **BOISSEAU_DENIS_Projet_PerceiverIO**.\n",
    "\n",
    "Le but de cet exemple est d'aider à la compréhension de l'utilisation de l'outil de deep\n",
    " learning **PerceiverIO** créé par *DeepMind* et d'évaluer ses performances.\n",
    "\n",
    "Les éléments fournis sont les suivants:\n",
    "- jeu de données d'exemple (./data/exampleText.txt) sous la forme d'un fichier .txt, correspondant\n",
    " à un extrait du livre électronique libre de droits du Projet Gutenberg *History of the United States*\n",
    " par Charles A. Beard et Mary R. Beard et disponible à l'adresse\n",
    " https://www.digitalbook.io/txt/1/6/9/6/16960/16960.txt;\n",
    "- fichier d'instances sérialisées des hyperparamètres du modèle, entrainés par *Deepmind* et\n",
    " disponible à l'adresse https://storage.googleapis.com/perceiver_io/language_perceiver_io_bytes.pickle;\n",
    "- script pour l'évaluation des performances du modèle;"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Sommaire :\n",
    "1. [Chargement des Modules et configuration du modèle](#1-bullet)\n",
    "2. [Définition des fonctions pour utiliser le PerceiverIO](#2-bullet)\n",
    "3. [Chargement des hyperparamètres et du DataSet, et pré-traitement](#3-bullet)\n",
    "4. [Evaluation de la solution en local](#4-bullet)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Chargement des Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "# Haiku permet aux utilisateurs d'utiliser des modèles de POO tout en permettant un accès complet aux transformations de fonctions pures de JAX pour les reseaux neuronaux.\n",
    "import haiku as hk\n",
    "# JAX est concue pour le calcul numérique à haute performance, notamment pour la recherche en apprentissage automatique.\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "# NumPy ajoute un support pour les grands tableaux multidimensionnels et les matrices, ainsi qu'une grande collection de fonctions mathématiques pour opérer sur ces tableaux.\n",
    "import numpy as np\n",
    "# Pickle est un module permettant la (dé)sérialisation\n",
    "import pickle\n",
    "\n",
    "from perceiver import *\n",
    "import random_masked_language as rml"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "#@title Model config\n",
    "D_MODEL = 768\n",
    "D_LATENTS = 1280\n",
    "MAX_SEQ_LEN = 2048\n",
    "\n",
    "encoder_config = dict(\n",
    "    num_self_attends_per_block=26,\n",
    "    num_blocks=1,\n",
    "    z_index_dim=256,\n",
    "    num_z_channels=D_LATENTS,\n",
    "    num_self_attend_heads=8,\n",
    "    num_cross_attend_heads=8,\n",
    "    qk_channels=8 * 32,\n",
    "    v_channels=D_LATENTS,\n",
    "    use_query_residual=True,\n",
    "    cross_attend_widening_factor=1,\n",
    "    self_attend_widening_factor=1)\n",
    "\n",
    "decoder_config = dict(\n",
    "    output_num_channels=D_LATENTS,\n",
    "    position_encoding_type='trainable',\n",
    "    output_index_dims=MAX_SEQ_LEN,\n",
    "    num_z_channels=D_LATENTS,\n",
    "    qk_channels=8 * 32,\n",
    "    v_channels=D_MODEL,\n",
    "    num_heads=8,\n",
    "    final_project=False,\n",
    "    use_query_residual=False,\n",
    "    trainable_position_encoding_kwargs=dict(num_channels=D_MODEL))\n",
    "\n",
    "# The tokenizer is just UTF-8 encoding (with an offset)\n",
    "tokenizer = bytes_tokenizer.BytesTokenizer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 2. Définition des fonctions pour utiliser le PerceiverIO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# Agrandit les tableaux inputs et input_mask pour qu'ils aient\n",
    "# une taille de max_sequence_length, et les remplit avec des 0\n",
    "def pad(max_sequence_length: int, inputs, input_mask):\n",
    "  input_len = inputs.shape[1]\n",
    "  assert input_len <= max_sequence_length\n",
    "  pad_len = max_sequence_length - input_len\n",
    "  padded_inputs = np.pad(\n",
    "      inputs,\n",
    "      pad_width=((0, 0), (0, pad_len)),\n",
    "      constant_values=tokenizer.pad_token)\n",
    "  padded_mask = np.pad(\n",
    "      input_mask,\n",
    "      pad_width=((0, 0), (0, pad_len)),\n",
    "      constant_values=0)\n",
    "  return padded_inputs, padded_mask"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "#@title Decoding Perceiver Model\n",
    "def apply_perceiver(\n",
    "    inputs: jnp.ndarray, input_mask: jnp.ndarray) -> jnp.ndarray:\n",
    "  \"\"\"Runs a forward pass on the Perceiver.\n",
    "\n",
    "  Args:\n",
    "    inputs: input bytes, an int array of shape [B, T]\n",
    "    input_mask: Array of shape indicating which entries are valid and which are\n",
    "      masked. A truthy value indicates that the entry is valid.\n",
    "\n",
    "  Returns:\n",
    "    The output logits, an array of shape [B, T, vocab_size].\n",
    "  \"\"\"\n",
    "  assert inputs.shape[1] == MAX_SEQ_LEN\n",
    "  # EXCEPTION A GERER : LE TEXTE EST TROP LONG, IL FAUT LE SEPARER EN DES ENSEMBLES DE\n",
    "  # PHRASES DE MOINS DE MAX_SEQ_LEN CARACTRES\n",
    "\n",
    "  # https://gdcoder.com/what-is-an-embedding-layer/\n",
    "  # Une couche d'integration convertie l'input en un ensemble de vecteurs\n",
    "  # d'integration dont les tailles sont optimisees pour le calcul\n",
    "\n",
    "  # Creation de la couche d'integration selon le nombre de mots distincts dans\n",
    "  # le training set et la dimension voulue des vecteurs d'integrations\n",
    "  embedding_layer = hk.Embed(\n",
    "      vocab_size=tokenizer.vocab_size,\n",
    "      embed_dim=D_MODEL)\n",
    "  # Conversion de l'input pour rentrer dans la 1ere couche (couche d'integration)\n",
    "  embedded_inputs = embedding_layer(inputs)\n",
    "\n",
    "  # Taille de la conversion de l'input\n",
    "  batch_size = embedded_inputs.shape[0]\n",
    "\n",
    "  # Parametres de construction des informations entrainables a propos de\n",
    "  # la position des mots dans la phrase\n",
    "  input_pos_encoding = perceiver.position_encoding.TrainablePositionEncoding(\n",
    "      index_dim=MAX_SEQ_LEN, num_channels=D_MODEL)\n",
    "  #print(input_pos_encoding(batch_size))\n",
    "  # Ajout des informations de position des mots a l'input\n",
    "  embedded_inputs = embedded_inputs + input_pos_encoding(batch_size)\n",
    "  # Initialisation du PerceiverIO\n",
    "  perceiver_mod = perceiver.Perceiver(\n",
    "      encoder=perceiver.PerceiverEncoder(**encoder_config),\n",
    "      decoder=perceiver.BasicDecoder(**decoder_config))\n",
    "  # Stockage dans output du resultat de l'execution du PerceiverIO a partir de la 1ere couche\n",
    "  output_embeddings = perceiver_mod(\n",
    "      embedded_inputs, is_training=False, input_mask=input_mask, query_mask=input_mask)\n",
    "\n",
    "  # Redimensionnement et decodage de l'output\n",
    "  logits = io_processors.EmbeddingDecoder(\n",
    "      embedding_matrix=embedding_layer.embeddings)(output_embeddings)\n",
    "  return logits\n",
    "\n",
    "# La transformation de la fonction lui permettra plus tard de lui\n",
    "# passer des parametres pre-enregistres\n",
    "# input_pos_encoding sera notamment ecrase par celui pre-enregistre\n",
    "apply_perceiver = hk.transform(apply_perceiver).apply"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 3. Chargement des hyperparamètres et du DataSet, et pré-traitement"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Des hyperparametres ont etes charges.\n"
     ]
    }
   ],
   "source": [
    "# On deserialise les valeurs des hyperparametres du modele.\n",
    "\n",
    "with open(\"./data/language_perceiver_io_bytes.pickle\", \"rb\") as f:\n",
    "  params = pickle.loads(f.read())\n",
    "\n",
    "#if type(params).__name__ == \"FlatMapping\":\n",
    "    #print(\"Des hyperparametres ont etes charges.\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extrait: \n",
      "In the period between the landing of the English at Jamestown, Virginia,\n",
      "in 1607, and the close of t\n",
      "\n",
      "Nombre de phrases trop longues : 0\n"
     ]
    }
   ],
   "source": [
    "# On prend un texte pour les tests\n",
    "with open('./data/exampleText.txt', 'r') as f:\n",
    "    inputs_str = f.read()\n",
    "f.close()\n",
    "'''\n",
    "if len(inputs_str) > 0:\n",
    "    if len(inputs_str) < 100:\n",
    "        print(inputs_str)\n",
    "    else:\n",
    "        print(\"Extrait: \\n\"+inputs_str[0:100])\n",
    "    print()\n",
    "'''\n",
    "#pre-traitement des donnees\n",
    "inputs_str = inputs_str.replace('\\n', ' ')\n",
    "inputs_str = inputs_str.replace('  ', ' ')\n",
    "inputs_str = inputs_str.replace('--a', '')\n",
    "inputs_str = inputs_str.replace('--', '-')\n",
    "inputs_str = inputs_str.split(\". \")\n",
    "initial_len_inputs_str = len(inputs_str)\n",
    "for sentenceIndex in range(len(inputs_str)):\n",
    "    if len(inputs_str[sentenceIndex]) > MAX_SEQ_LEN:\n",
    "        del inputs_str[sentenceIndex]\n",
    "        sentenceIndex -= 1\n",
    "    else:\n",
    "        inputs_str[sentenceIndex] += '.'\n",
    "print(\"Nombre de phrases trop longues : \" + str(initial_len_inputs_str-len(inputs_str)))\n",
    "\n",
    "dataSize = len(inputs_str)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de phrases a tester: 54\n"
     ]
    }
   ],
   "source": [
    "# Initialisation des variables pour chaque phrase\n",
    "data = [\n",
    "    {\n",
    "        'input_str':inputs_str[sentenceIndex],\n",
    "        'maskedwords':None,\n",
    "        'maskedwordsIndexesInStr':None,\n",
    "        'input_tokens':None,\n",
    "        'inputs':None,\n",
    "        'input_mask':None,\n",
    "        'predicted_words':None,\n",
    "        'efficiency':None\n",
    "    } for sentenceIndex in range(dataSize)\n",
    "]\n",
    "\n",
    "#percentage = 20\n",
    "for iterator in range(dataSize):\n",
    "    data[iterator]['maskedwords'], maskedwordsIndexesInData = rml.chooseMaskedWords(data[iterator]['input_str'], percentage)\n",
    "    data[iterator]['maskedwordsIndexesInStr'] = rml.findIndexes(data[iterator]['input_str'], maskedwordsIndexesInData)\n",
    "    if len(data[iterator]['maskedwordsIndexesInStr']) % 2 == 1:\n",
    "        '''\n",
    "        print(\"ANOMALIE (phrase n°\",iterator,\") :   len(maskedwordsIndexesInStr) devrait etre pair... or == \", len(data[iterator]['maskedwordsIndexesInStr']))\n",
    "        print(data[iterator]['maskedwordsIndexesInStr'])\n",
    "        print(maskedwordsIndexesInData)\n",
    "        print(data[iterator]['input_str'])\n",
    "        print(\" et devrait aussi etre == 2*len(maskedwordsIndexesInData)...\\n\\t\\tsachant que len(maskedwordsIndexesInData) == \", len(maskedwordsIndexesInData))\n",
    "        print(\" donc il manque un index dans maskedwordsIndexesInStr\")\n",
    "        print()\n",
    "        '''\n",
    "    data[iterator]['input_tokens'] = rml.inputWithMaskedWords(data[iterator]['input_str'], data[iterator]['maskedwordsIndexesInStr'])\n",
    "\n",
    "print(\"Nombre de phrases a tester: \" + str(dataSize))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 4. Evaluation de la solution en local"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple de inputs : [[ 79 116  38 ...   0   0   0]]\n",
      "Exemple de input_mask : [[1 1 1 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "for iterator in range(dataSize):\n",
    "    # inputs est le tableau d'entiers avec une dimension supplementaire\n",
    "    # c'est comme si on mettait le tableau inputs a l'interieur d'un nouveau tableau\n",
    "    data[iterator]['inputs'] = data[iterator]['input_tokens'][None]\n",
    "\n",
    "    # input_mask est l'equivalent unitaire de inputs :\n",
    "    # pour toutes les valeurs d'inputs, on met un 1\n",
    "    data[iterator]['input_mask'] = np.ones_like(data[iterator]['inputs'])\n",
    "\n",
    "    data[iterator]['inputs'], data[iterator]['input_mask'] = pad(MAX_SEQ_LEN, data[iterator]['inputs'], data[iterator]['input_mask'])\n",
    "\n",
    "#print(\"Exemple de inputs :\", data[0]['inputs'])\n",
    "#print(\"Exemple de input_mask :\", data[0]['input_mask'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progression : 1%\n",
      "Progression : 5%\n",
      "Progression : 11%\n",
      "Progression : 16%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_191/1596548690.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0;31m# la prediction sous forme d'entiers est constituee des valeurs maximales\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     \u001B[0;31m# aux coordonnees du masque sur la 1ere dimension de out : ( type(out[0]) == int[] )\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 6\u001B[0;31m     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapply_perceiver\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrng\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrng\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'inputs'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_mask\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'input_mask'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m     \u001B[0mdata\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'predicted_words'\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto_string\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0margmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/transform.py\u001B[0m in \u001B[0;36mapply_fn\u001B[0;34m(params, *args, **kwargs)\u001B[0m\n\u001B[1;32m    123\u001B[0m           \"name (e.g. `f.apply(.., state=my_state)`)\")\n\u001B[1;32m    124\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 125\u001B[0;31m     \u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    126\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    127\u001B[0m       raise ValueError(\"If your transformed function uses `hk.{get,set}_state` \"\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/transform.py\u001B[0m in \u001B[0;36mapply_fn\u001B[0;34m(params, state, rng, *args, **kwargs)\u001B[0m\n\u001B[1;32m    311\u001B[0m         rng, err_msg=(APPLY_RNG_STATE_ERROR if state else APPLY_RNG_ERROR))\n\u001B[1;32m    312\u001B[0m     \u001B[0;32mwith\u001B[0m \u001B[0mbase\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnew_context\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mparams\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstate\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mstate\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mrng\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mrng\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 313\u001B[0;31m       \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    314\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mctx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollect_state\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    315\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_191/3500257900.py\u001B[0m in \u001B[0;36mapply_perceiver\u001B[0;34m(inputs, input_mask)\u001B[0m\n\u001B[1;32m     43\u001B[0m       decoder=perceiver.BasicDecoder(**decoder_config))\n\u001B[1;32m     44\u001B[0m   \u001B[0;31m# Stockage dans output du resultat de l'execution du PerceiverIO a partir de la 1ere couche\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 45\u001B[0;31m   output_embeddings = perceiver_mod(\n\u001B[0m\u001B[1;32m     46\u001B[0m       embedded_inputs, is_training=False, input_mask=input_mask, query_mask=input_mask)\n\u001B[1;32m     47\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    426\u001B[0m         \u001B[0mf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstateful\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnamed_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlocal_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    427\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 428\u001B[0;31m       \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    429\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    430\u001B[0m       \u001B[0;31m# Module names are set in the constructor. If `f` is the constructor then\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py\u001B[0m in \u001B[0;36mrun_interceptors\u001B[0;34m(bound_method, method_name, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m   \u001B[0;34m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0minterceptor_stack\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 279\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mbound_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    280\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m   ctx = MethodContext(module=self,\n",
      "\u001B[0;32m/mnt/c/Users/sarah/Documents/Polytech/S7/DI4ProjetPerceiverIO/perceiver/perceiver.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, inputs, is_training, subsampled_output_points, pos, input_mask, query_mask)\u001B[0m\n\u001B[1;32m    373\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    374\u001B[0m     \u001B[0;31m# Run the network forward:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 375\u001B[0;31m     z = self._encoder(inputs, encoder_query,\n\u001B[0m\u001B[1;32m    376\u001B[0m                       is_training=is_training, input_mask=input_mask)\n\u001B[1;32m    377\u001B[0m     _, output_modality_sizes = self._decoder.output_shape(\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    426\u001B[0m         \u001B[0mf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstateful\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnamed_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlocal_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    427\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 428\u001B[0;31m       \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    429\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    430\u001B[0m       \u001B[0;31m# Module names are set in the constructor. If `f` is the constructor then\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py\u001B[0m in \u001B[0;36mrun_interceptors\u001B[0;34m(bound_method, method_name, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m   \u001B[0;34m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0minterceptor_stack\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 279\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mbound_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    280\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m   ctx = MethodContext(module=self,\n",
      "\u001B[0;32m/mnt/c/Users/sarah/Documents/Polytech/S7/DI4ProjetPerceiverIO/perceiver/perceiver.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, inputs, z, is_training, input_mask)\u001B[0m\n\u001B[1;32m    468\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_blocks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    469\u001B[0m       \u001B[0;32mfor\u001B[0m \u001B[0mself_attend\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mself_attends\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 470\u001B[0;31m         \u001B[0mz\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself_attend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mz\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mis_training\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mis_training\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    471\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mz\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    472\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    426\u001B[0m         \u001B[0mf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstateful\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnamed_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlocal_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    427\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 428\u001B[0;31m       \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    429\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    430\u001B[0m       \u001B[0;31m# Module names are set in the constructor. If `f` is the constructor then\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py\u001B[0m in \u001B[0;36mrun_interceptors\u001B[0;34m(bound_method, method_name, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m   \u001B[0;34m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0minterceptor_stack\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 279\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mbound_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    280\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m   ctx = MethodContext(module=self,\n",
      "\u001B[0;32m/mnt/c/Users/sarah/Documents/Polytech/S7/DI4ProjetPerceiverIO/perceiver/perceiver.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, inputs, attention_mask, is_training)\u001B[0m\n\u001B[1;32m    236\u001B[0m     \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    237\u001B[0m     \u001B[0mqkv_inputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer_norm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 238\u001B[0;31m     attention = Attention(\n\u001B[0m\u001B[1;32m    239\u001B[0m         \u001B[0mnum_heads\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_heads\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    240\u001B[0m         \u001B[0minit_scale\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_att_init_scale\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    426\u001B[0m         \u001B[0mf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstateful\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnamed_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlocal_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    427\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 428\u001B[0;31m       \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    429\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    430\u001B[0m       \u001B[0;31m# Module names are set in the constructor. If `f` is the constructor then\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py\u001B[0m in \u001B[0;36mrun_interceptors\u001B[0;34m(bound_method, method_name, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m   \u001B[0;34m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0minterceptor_stack\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 279\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mbound_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    280\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m   ctx = MethodContext(module=self,\n",
      "\u001B[0;32m/mnt/c/Users/sarah/Documents/Polytech/S7/DI4ProjetPerceiverIO/perceiver/perceiver.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, inputs_q, inputs_kv, attention_mask)\u001B[0m\n\u001B[1;32m    158\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    159\u001B[0m     \u001B[0;31m# Project QKV to a common feature dimension.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 160\u001B[0;31m     \u001B[0mq\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconv_1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_qk_channels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minit_scale\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_scale\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs_q\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    161\u001B[0m     \u001B[0mk\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconv_1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_qk_channels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minit_scale\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_scale\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs_kv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    162\u001B[0m     \u001B[0mv\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconv_1d\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_v_channels\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minit_scale\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_init_scale\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs_kv\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py\u001B[0m in \u001B[0;36mwrapped\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    426\u001B[0m         \u001B[0mf\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mstateful\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnamed_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlocal_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    427\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 428\u001B[0;31m       \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    429\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    430\u001B[0m       \u001B[0;31m# Module names are set in the constructor. If `f` is the constructor then\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/module.py\u001B[0m in \u001B[0;36mrun_interceptors\u001B[0;34m(bound_method, method_name, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m   \u001B[0;34m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    278\u001B[0m   \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0minterceptor_stack\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 279\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0mbound_method\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    280\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    281\u001B[0m   ctx = MethodContext(module=self,\n",
      "\u001B[0;32m~/.local/lib/python3.8/site-packages/haiku/_src/basic.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, inputs, precision)\u001B[0m\n\u001B[1;32m    178\u001B[0m     \u001B[0mw\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mhk\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_parameter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"w\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0minput_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_size\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mw_init\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    179\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 180\u001B[0;31m     \u001B[0mout\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjnp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mw\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprecision\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mprecision\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    181\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    182\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_bias\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "rng = jax.random.PRNGKey(1)  # Unused\n",
    "\n",
    "for iterator in range(dataSize):\n",
    "    # la prediction sous forme d'entiers est constituee des valeurs maximales\n",
    "    # aux coordonnees du masque sur la 1ere dimension de out : ( type(out[0]) == int[] )\n",
    "    out = apply_perceiver(params, rng=rng, inputs=data[iterator]['inputs'], input_mask=data[iterator]['input_mask'])\n",
    "    data[iterator]['predicted_words'] = tokenizer.to_string(out[0].argmax(axis=-1))\n",
    "\n",
    "    progression = int((iterator+1)/dataSize*100)\n",
    "    if progression % 5 < 2:\n",
    "        print(\"Progression : \"+str(progression)+\"%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = open('./data/analysis_results.txt', \"w\")\n",
    "\n",
    "rng = jax.random.PRNGKey(1)  # Unused\n",
    "\n",
    "for iterator in range(dataSize):\n",
    "    predictedSentence = rml.stringWithNewWords(data[iterator]['input_str'], data[iterator]['predicted_words'], data[iterator]['maskedwordsIndexesInStr'])\n",
    "    masked_tokens_predictions = rml.extractWordsByIndexes(data[iterator]['predicted_words'], data[iterator]['maskedwordsIndexesInStr'])\n",
    "\n",
    "    results.write(\"-\"+str(iterator+1)+\"-\\n\")\n",
    "    results.write(\"-Sentence:\"+\"\\n\")\n",
    "    results.write(data[iterator]['input_str']+\"\\n\")\n",
    "    #results.write(\"Local sentence with masked bytes:\"+\"\\n\")\n",
    "    #results.write(tokenizer.to_string(data[iterator]['input_tokens'])+\"\\n\")\n",
    "    results.write(\"-Sentence predicted:\"+\"\\n\")\n",
    "    results.write(predictedSentence+\"\\n\")\n",
    "\n",
    "    results.write(\"-Word-by-word prediction:\"+\"\\n\")\n",
    "    for local_masked_token_prediction in masked_tokens_predictions:\n",
    "        results.write(\"\\t>\"+local_masked_token_prediction+\"\\n\")\n",
    "\n",
    "    efficiency = data[iterator]['efficiency'] = \\\n",
    "        rml.computeEfficiency(data[iterator]['input_str'], predictedSentence, data[iterator]['maskedwordsIndexesInStr'])\n",
    "    results.write(\"-Efficiency:\"+\"\\n\")\n",
    "    if efficiency is not None:\n",
    "        results.write('{:.2f}%'.format(efficiency * 100)+\"\\n\\n\")\n",
    "    else:\n",
    "        results.write(\"None\"+\"\\n\\n\")\n",
    "\n",
    "results.close()\n",
    "#print(\"Outputs disponibles dans \" + results.name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Etude des résultats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "efficiency_samples = [\n",
    "    \"\"\"\n",
    "    {\n",
    "        'data_iterator':int,\n",
    "        'efficiency':float,\n",
    "    }\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "model_efficiency = 0\n",
    "for iterator in range(dataSize):\n",
    "    efficiency = data[iterator]['efficiency']\n",
    "    if efficiency is not None:\n",
    "        efficiency_samples.append( (iterator, efficiency) )\n",
    "        model_efficiency += efficiency\n",
    "model_efficiency /= len(efficiency_samples)\n",
    "\n",
    "print(\"Nombre de resultats: \" + str(len(efficiency_samples)))\n",
    "print()\n",
    "print(\"Efficacite du modele sur \" + f.name)\n",
    "print(\"avec un pourcentage de masquage de \"+ str(percentage) + \": \")\n",
    "print('{:.2f}%'.format(model_efficiency * 100))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}